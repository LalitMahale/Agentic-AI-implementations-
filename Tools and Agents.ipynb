{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c4fafd-21d6-454a-b014-aa5f212ef3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ddfa97-8090-483a-ab20-a9bc80f0983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(api_key=os.getenv(\"GOOGLE_API_KEY\"),model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa67332-8e65-4fa4-ba46-9258e7591a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d70f49-2d17-4c85-a921-0480cc5e6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akrivia\\miniconda3\\envs\\genai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\akrivia\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = HuggingFaceEmbeddings(model = \"all-MiniLM-L6-v2\")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d5ff4-4a66-4379-a088-0d501ae10474",
   "metadata": {},
   "source": [
    "## Pre Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98607b4-b262-4133-bbf5-db0adaa1daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c018cee-ebbf-42d2-aebd-fc48d3415178",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198c2428-ca3d-4e9d-91ae-49c76f0bec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akrivia\\miniconda3\\envs\\genai\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\akrivia\\miniconda3\\envs\\genai\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Page: Large language model\\nSummary: A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation.\\nThe largest and most capable LLMs are generative pretrained transformers (GPTs), which are largely used in generative chatbots such as ChatGPT, Gemini or Claude. LLMs can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.\\n\\nPage: Master of Laws\\nSummary: A Master of Laws (M.L. or LL.M.; Latin: Magister Legum or Legum Magister) is a postgraduate academic degree, pursued by those either holding an undergraduate academic law degree or a professional law degree.\\nIn many jurisdictions, the LL.M. is an advanced professional degree for those already admitted to legal practice.\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run({\"query\":\"llm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e6680-11e1-4d03-9fbe-adbbbc4436a8",
   "metadata": {},
   "source": [
    "## Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cec7c6-0841-4b28-ad3d-7b4a3db5250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e11936-200c-43ee-ad43-abb344c7fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_count(sentence:str) ->int:\n",
    "    \"\"\"Return the Number of words\"\"\"\n",
    "    return len(sentence.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ace1f7c8-dbaa-48ec-8aac-8cb8152032e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"Multipy two numbers\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "854e043a-ac70-4d5d-9648-52fefb87b27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_count.invoke(\"hi i am lalit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec8cbdf6-0f86-4433-9c64-c154f3eb65cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "Multipy two numbers\n"
     ]
    }
   ],
   "source": [
    "print(multiply.args)\n",
    "print(num_multiply.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6faa3d86-c903-4720-a79d-8ea5d677ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summation(a:int,b:int) -> int:\n",
    "    \"\"\"Adding two numbers\"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e555092-028f-40f3-9ffa-52530d40789c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Adding two numbers',\n",
       " {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation.description, summation.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6f79f-95fc-4a1f-94ce-413bde8063ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
